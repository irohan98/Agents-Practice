{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ssxw6WRNkQnx"
      ],
      "authorship_tag": "ABX9TyPAXG8sJV098os3DByUvI6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irohan98/Agents-Practice/blob/main/recipe_ingestion_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Packages"
      ],
      "metadata": {
        "id": "Ssxw6WRNkQnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "R_YE53iABB2q"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "!pip install openai-whisper yt-dlp sentence-transformers pandas -q\n",
        "!apt-get update && apt-get install -y ffmpeg -q  # (For Linux/Colab systems)\n",
        "!pip install youtube-transcript-api --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from typing import Dict, List\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import pandas as pd\n",
        "import whisper\n",
        "import yt_dlp\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "76zLv58aBGVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "2tL6gTBDkx7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Whisper model for audio transcription\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "# Load SentenceTransformer for embedding recipes\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Recipe store to hold ingested recipes (mock DB)\n",
        "recipe_store = []"
      ],
      "metadata": {
        "id": "1g5Rd4HsBMIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Youtube Scrapping - v2\n",
        "\n",
        "References: https://colab.research.google.com/drive/1KOlGHd3Rqs_w6_6F_LiqTF1Dcga_XZBk?usp=sharing#scrollTo=jBTs4wnBnH1G"
      ],
      "metadata": {
        "id": "g76431ftSgYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import glob\n",
        "\n",
        "def get_video_id(link: str) -> str:\n",
        "    parsed = urlparse(link)\n",
        "    if 'youtube.com' in parsed.netloc:\n",
        "        return parse_qs(parsed.query).get('v', [''])[0]\n",
        "    elif 'youtu.be' in parsed.netloc:\n",
        "        return parsed.path.lstrip('/')\n",
        "    return \"\"\n",
        "\n",
        "def try_youtube_captions(video_id: str) -> str:\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi().get_transcript(video_id)\n",
        "        return \" \".join([t[\"text\"] for t in transcript])\n",
        "    except TranscriptsDisabled:\n",
        "        print(\"âš ï¸ Captions are disabled for this video.\")\n",
        "    except NoTranscriptFound:\n",
        "        print(\"âš ï¸ No transcript found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Caption extraction failed: {e}\")\n",
        "    return \"\"\n",
        "\n",
        "def transcribe_audio_with_yt_dlp(link: str, use_cookies: bool = False, cookies_path: str = \"youtube_cookies.txt\") -> str:\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'quiet': False,\n",
        "        'outtmpl': '/tmp/audio.%(ext)s',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "    }\n",
        "    if use_cookies:\n",
        "        ydl_opts['cookiefile'] = cookies_path\n",
        "\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([link])\n",
        "\n",
        "        audio_files = glob.glob(\"/tmp/audio*.mp3\")\n",
        "        if not audio_files:\n",
        "            raise FileNotFoundError(\"No audio file found.\")\n",
        "        audio_path = audio_files[0]\n",
        "\n",
        "        print(f\"ðŸŽ§ Transcribing audio: {audio_path}\")\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        return result['text']\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Audio transcription failed: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def ingest_recipe_smart(link: str, cookies_path: str = \"youtube_cookies.txt\") -> str:\n",
        "    video_id = get_video_id(link)\n",
        "    if not video_id:\n",
        "        return \"Invalid YouTube link.\"\n",
        "\n",
        "    print(\"ðŸ” Trying captions...\")\n",
        "    text = try_youtube_captions(video_id)\n",
        "    if text:\n",
        "        print(\"âœ… Captions found.\")\n",
        "        return text\n",
        "\n",
        "    print(\"ðŸŒ€ Trying audio transcription without cookies...\")\n",
        "    text = transcribe_audio_with_yt_dlp(link, use_cookies=False)\n",
        "    if text:\n",
        "        print(\"âœ… Transcription without cookies succeeded.\")\n",
        "        return text\n",
        "\n",
        "    print(\"ðŸ” Trying with cookies...\")\n",
        "    text = transcribe_audio_with_yt_dlp(link, use_cookies=True, cookies_path=cookies_path)\n",
        "    if text:\n",
        "        print(\"âœ… Transcription with cookies succeeded.\")\n",
        "        return text\n",
        "\n",
        "    return \"âŒ All attempts failed.\""
      ],
      "metadata": {
        "id": "6_v_1u9ZSgC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST-v2\n",
        "# link = \"https://youtu.be/2uYoqclu6so\"\n",
        "link = \"https://youtu.be/2uYoqclu6so?si=4au4jhBN33YT60OQ\"\n",
        "text = ingest_recipe_smart(link)\n",
        "print(text[:500])"
      ],
      "metadata": {
        "id": "14y04BmWSj_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZYnQfqvSj45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### YouTube Scrapping - v1"
      ],
      "metadata": {
        "id": "GwVyD_c4kvlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def is_youtube_link(link: str) -> bool:\n",
        "    parsed = urlparse(link)\n",
        "    return \"youtube.com\" in parsed.netloc or \"youtu.be\" in parsed.netloc\n",
        "\n",
        "def transcribe_youtube(link: str, cookies_path: str = \"youtube_cookies.txt\") -> str:\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'quiet': False,\n",
        "        'outtmpl': '/tmp/audio.%(ext)s',  # Allow yt-dlp to set proper extension\n",
        "        'cookiefile': cookies_path,\n",
        "        'postprocessors': [{  # Extract audio as mp3\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "    }\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([link])\n",
        "\n",
        "        # Find the downloaded mp3 file in /tmp\n",
        "        files = glob.glob(\"/tmp/audio*.mp3\")\n",
        "        if not files:\n",
        "            raise FileNotFoundError(\"Audio file not found after download\")\n",
        "        audio_path = files[0]\n",
        "\n",
        "        print(f\"Using audio file: {audio_path}\")\n",
        "\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        return result['text']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error downloading/transcribing: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "\n",
        "def extract_recipe_from_text(text: str) -> Dict:\n",
        "    steps = re.split(r\"\\d+\\.\", text)\n",
        "    steps = [step.strip() for step in steps if len(step.strip()) > 10]\n",
        "    return {\n",
        "        \"raw_text\": text,\n",
        "        \"steps\": steps,\n",
        "        \"num_steps\": len(steps),\n",
        "        \"tags\": [],  # Placeholder for later\n",
        "    }\n",
        "\n",
        "\n",
        "def store_recipe(recipe_data: Dict):\n",
        "    embedding = embedding_model.encode(recipe_data['raw_text'])\n",
        "    recipe_data['embedding'] = embedding\n",
        "    recipe_store.append(recipe_data)\n"
      ],
      "metadata": {
        "id": "HgQn9yZmBN5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ingest_recipe_from_youtube(link: str, cookies_path: str = \"youtube_cookies.txt\"):\n",
        "    if not is_youtube_link(link):\n",
        "        return \"Invalid YouTube URL.\"\n",
        "\n",
        "    text = transcribe_youtube(link, cookies_path)\n",
        "    if not text:\n",
        "        return \"Failed to transcribe video.\"\n",
        "\n",
        "    display(Markdown(f\"### Transcribed Text\\n{text[:500]}...\"))\n",
        "\n",
        "    recipe = extract_recipe_from_text(text)\n",
        "    store_recipe(recipe) # Use store_recipe here\n",
        "\n",
        "    display(Markdown(\"### Extracted Steps\"))\n",
        "    for i, step in enumerate(recipe['steps']):\n",
        "        display(Markdown(f\"**Step {i+1}:** {step}\"))\n",
        "\n",
        "    return recipe"
      ],
      "metadata": {
        "id": "yHW2hIG_BQvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample test link\n",
        "youtube_link = \"https://youtu.be/2uYoqclu6so?si=4au4jhBN33YT60OQ\"\n",
        "result = ingest_recipe_from_youtube(youtube_link)"
      ],
      "metadata": {
        "id": "82ZgzNYEBU2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instagram Scrapping"
      ],
      "metadata": {
        "id": "yJM2IMsUkJzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instaloader"
      ],
      "metadata": {
        "id": "WV8sy8S3kKJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import instaloader\n",
        "\n",
        "# Create instaloader instance\n",
        "L = instaloader.Instaloader(download_video_thumbnails=False, download_geotags=False, download_comments=False)\n"
      ],
      "metadata": {
        "id": "zdEtRzV8kKMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only needed if you want to access private content or saved reels\n",
        "# L.login('your_username', 'your_password')  # Optional"
      ],
      "metadata": {
        "id": "LUlAOQqMlF8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_instagram_text(link: str) -> str:\n",
        "    shortcode = None\n",
        "    match = re.search(r\"instagram\\.com/(reel|p)/([a-zA-Z0-9_-]+)\", link)\n",
        "    if match:\n",
        "        shortcode = match.group(2)\n",
        "    else:\n",
        "        return \"Invalid Instagram link.\"\n",
        "\n",
        "    post = instaloader.Post.from_shortcode(L.context, shortcode)\n",
        "\n",
        "    caption = post.caption or \"No caption available.\"\n",
        "    video_url = post.video_url if post.is_video else None\n",
        "\n",
        "    # Optional: download video audio for Whisper transcription\n",
        "    if video_url:\n",
        "        audio_path = \"/tmp/insta_audio.mp3\"\n",
        "        os.system(f\"yt-dlp -x --audio-format mp3 -o '{audio_path}' '{video_url}'\")\n",
        "        transcript = whisper_model.transcribe(audio_path)['text']\n",
        "        return f\"{caption}\\n\\nTranscribed Audio:\\n{transcript}\"\n",
        "    else:\n",
        "        return caption"
      ],
      "metadata": {
        "id": "hTxDg5LxlF5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ingest_recipe_from_instagram(link: str):\n",
        "    print(\"Fetching Instagram content...\")\n",
        "    text = extract_instagram_text(link)\n",
        "    display(Markdown(f\"### Extracted/Transcribed Text\\n{text[:500]}...\"))\n",
        "\n",
        "    recipe = extract_recipe_from_text(text)\n",
        "    store_recipe(recipe)\n",
        "\n",
        "    display(Markdown(\"### Extracted Steps\"))\n",
        "    for i, step in enumerate(recipe['steps']):\n",
        "        display(Markdown(f\"**Step {i+1}:** {step}\"))\n",
        "\n",
        "    return recipe"
      ],
      "metadata": {
        "id": "zi6VWkLIlF2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Reel/Post\n",
        "insta_link = \"https://www.instagram.com/reel/DGtu1YbPwd9/?igsh=MTBhcDk1Ymk2ZzFoYg==\"\n",
        "result = ingest_recipe_from_instagram(insta_link)"
      ],
      "metadata": {
        "id": "sQslAtCGlFzY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Scrapping"
      ],
      "metadata": {
        "id": "geSxVGbfumIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ingest_recipe_from_text(raw_text: str):\n",
        "    display(Markdown(\"### Input Recipe Text\"))\n",
        "    display(Markdown(raw_text[:500] + (\"...\" if len(raw_text) > 500 else \"\")))\n",
        "\n",
        "    recipe = extract_recipe_from_text(raw_text)\n",
        "    recipe['raw_text'] = raw_text  # Ensure raw_text is included\n",
        "    recipe['embedding'] = embedding_model.encode(raw_text)\n",
        "\n",
        "    # store_recipe_to_vector_db(recipe)\n",
        "\n",
        "    display(Markdown(\"### Extracted Steps\"))\n",
        "    for i, step in enumerate(recipe['steps']):\n",
        "        display(Markdown(f\"**Step {i+1}:** {step}\"))\n",
        "\n",
        "    return recipe"
      ],
      "metadata": {
        "id": "T4X-pUvruksj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paste or type any recipe here\n",
        "sample_text = \"\"\"\n",
        "Masala French Toast\n",
        "\n",
        "1. Break 2 eggs into a bowl.\n",
        "2. Add 1 chopped green chili, 1/2 tsp red chili powder, salt, and some chopped cilantro.\n",
        "3. Mix well with a fork.\n",
        "4. Dip bread slices into the mixture.\n",
        "5. Toast both sides on a buttered pan until golden brown.\n",
        "6. Serve hot with ketchup or chutney.\n",
        "\"\"\"\n",
        "\n",
        "recipe = ingest_recipe_from_text(sample_text)\n"
      ],
      "metadata": {
        "id": "2rNZlQ3Yul1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HqIJptERulbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Store Recipes in FAISS + Metadata Index\n",
        "\n",
        "This step needs to be before ingestion\n",
        "\n",
        "After ingesting any recipe from any source, it should store it in FAISS immediately for future reference.\n",
        "\n",
        "STEPS:\n",
        "\n",
        "1. Setup the FAISS\n",
        "2. Store the Ingested Recipies from different sources in FAISS"
      ],
      "metadata": {
        "id": "cx0MxvzHpDZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "H2-IrJXWlXrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Define embedding dimension (must match your SentenceTransformer)\n",
        "embedding_dim = 384  # for 'all-MiniLM-L6-v2'\n",
        "\n",
        "# FAISS index (Flat L2 search for simplicity)\n",
        "faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "# Metadata store for structured search (can replace with SQLite later)\n",
        "metadata_store = []\n"
      ],
      "metadata": {
        "id": "TDC3GW5rpGRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_recipe_to_vector_db(recipe: Dict):\n",
        "    embedding = recipe['embedding']\n",
        "    if isinstance(embedding, list):\n",
        "        embedding = np.array(embedding).astype('float32')\n",
        "\n",
        "    # Add to FAISS\n",
        "    faiss_index.add(np.expand_dims(embedding, axis=0))\n",
        "\n",
        "    # Add to metadata store\n",
        "    metadata_store.append({\n",
        "        \"text\": recipe['raw_text'],\n",
        "        \"steps\": recipe['steps'],\n",
        "        \"num_steps\": recipe['num_steps'],\n",
        "        \"tags\": recipe.get(\"tags\", []),\n",
        "        # Add more filters later like cuisine, type, time etc.\n",
        "    })\n",
        "\n",
        "    print(f\"âœ… Recipe stored! Total stored: {len(metadata_store)}\")\n"
      ],
      "metadata": {
        "id": "Jj0tW7CKpGOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_recipe_to_vector_db(recipe)"
      ],
      "metadata": {
        "id": "PAWELTFhUcWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7_DsuoQUdoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After ingestion:\n",
        "# YT_recipe = ingest_recipe_from_youtube(\"https://youtu.be/2uYoqclu6so?si=4au4jhBN33YT60OQ\")\n",
        "# store_recipe_to_vector_db(YT_recipe)\n",
        "store_recipe_to_vector_db(result)"
      ],
      "metadata": {
        "id": "nifHPtrCpGLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function - This is done by the LLM after it gets the query\n",
        "\n",
        "def search_similar_recipes(query: str, top_k: int = 3):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    query_embedding = np.array(query_embedding).astype('float32')\n",
        "\n",
        "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "\n",
        "    print(\"ðŸ” Top Similar Recipes:\\n\")\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        meta = metadata_store[idx]\n",
        "        print(f\"ðŸ”¸ Match {i+1}: {meta['text'][:300]}...\\n---\\n\")\n"
      ],
      "metadata": {
        "id": "xTbAXrvgpGI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function - This is done by the LLM after it gets the query\n",
        "\n",
        "# search_similar_recipes(\"I want to make salmon with lime under 30 minutes\", top_k=1)\n",
        "search_similar_recipes(\"I want to make eggs under 30 minutes\", top_k=1)"
      ],
      "metadata": {
        "id": "AOYWZ9RepGGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use RAG using Gemini"
      ],
      "metadata": {
        "id": "slDPoYVlt5Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "id": "X6IusGCOpGDh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "F9b2B3a_t4zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_rag_response_with_gemini(user_query: str, top_k: int = 3) -> str:\n",
        "    # Embed query and search FAISS\n",
        "    query_embedding = embedding_model.encode([user_query])\n",
        "    query_embedding = np.array(query_embedding).astype('float32')\n",
        "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "\n",
        "    # Build context\n",
        "    context_snippets = []\n",
        "    for idx in indices[0]:\n",
        "        recipe = metadata_store[idx]\n",
        "        snippet = f\"Steps:\\n\" + \"\\n\".join(recipe['steps'][:6])\n",
        "        context_snippets.append(snippet)\n",
        "\n",
        "    context = \"\\n\\n---\\n\\n\".join(context_snippets)\n",
        "\n",
        "    prompt = f\"\"\"You are a helpful recipe assistant.\n",
        "\n",
        "User request: {user_query}\n",
        "\n",
        "Here are some recipes:\n",
        "\n",
        "{context}\n",
        "\n",
        "Please recommend the best-fitting recipe and explain why it was chosen.\n",
        "\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "5mx0PKv2t4xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Looking for a light Italian appetizer under 30 minutes\"\n",
        "response = generate_rag_response_with_gemini(query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "twHMvWy4t4t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pIoIDZ7t4rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvAXUGIpubWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFMKEuPlubTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFvGmFt_DLi7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}